{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The candidate shall develop a technology for a specific spam detection, based on the provenance and content of the email. An email shall be treated as spam when it comes from a mail domain (smtp sender) that is classified as spamming, or it contains a set of terms that are referrable to spam. The training phase shall deliver a model of spam that is compatible with the above specifications. \n",
    "\n",
    "The training set of the process can be found on https://www.kaggle.com/datasets/balaka18/email-spam-classification-dataset-csv and can be implemented either:\n",
    "\n",
    "- by using a naive Bayes classifier; \n",
    "\n",
    "- or by using a FFNN;\n",
    "\n",
    "- or by using an MLP with two layers.\n",
    "\n",
    "The technology is to be implemented by using either NLTK with Python or OpenNLP with Java. The solution shall be valued based on the correctness, completeness and consistency of the solution implemented. For the evaluation, we shall consider confusion matrix, with specific emphasis on the F1 measure.\n",
    "\n",
    "Overall, students shall deliver the solution via GitHub. On accessing the solution we value it by anti-cheating technologies, and therefore it will not be considered acceptable when more than 60% of the code is not original. Along with the solution, please upload also the confusion matrix and some analysis on the effectiveness. No value shall be given to solution strength. If a solution is not at the state-of-the-art, we consider it fine in any case, provided it comes along with the above characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impleamnets\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.classify.util import accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/silvergjeka/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/silvergjeka/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Email No.  the  to  ect  and  for  of    a  you  hou  ...  connevey  jay  \\\n",
      "0   Email 1    0   0    1    0    0   0    2    0    0  ...         0    0   \n",
      "1   Email 2    8  13   24    6    6   2  102    1   27  ...         0    0   \n",
      "2   Email 3    0   0    1    0    0   0    8    0    0  ...         0    0   \n",
      "3   Email 4    0   5   22    0    5   1   51    2   10  ...         0    0   \n",
      "4   Email 5    7   6   17    1    5   2   57    0    9  ...         0    0   \n",
      "\n",
      "   valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
      "0       0    0               0         0         0   0    0           0  \n",
      "1       0    0               0         0         0   1    0           0  \n",
      "2       0    0               0         0         0   0    0           0  \n",
      "3       0    0               0         0         0   0    0           0  \n",
      "4       0    0               0         0         0   1    0           0  \n",
      "\n",
      "[5 rows x 3002 columns]\n"
     ]
    }
   ],
   "source": [
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the dataset\n",
    "# url = \"https://www.kaggle.com/datasets/balaka18/email-spam-classification-dataset-csv\"\n",
    "# You will need to manually download the dataset from Kaggle and load it into pandas\n",
    "# Let's assume the dataset is named \"spam.csv\"\n",
    "df = pd.read_csv('emails.csv')\n",
    "\n",
    "# Check the first few rows of the dataset\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
